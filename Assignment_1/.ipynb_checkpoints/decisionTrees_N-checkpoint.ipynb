{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monkdata as m\n",
    "import numpy as np\n",
    "import dtree as dt\n",
    "import pandas as pd\n",
    "import drawtree_qt5 as drawt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.95711743 0.99980613]\n"
     ]
    }
   ],
   "source": [
    "datasets = [m.monk1, m.monk2, m.monk3]\n",
    "ent = np.zeros(len(datasets))\n",
    "for i, v in enumerate(datasets):\n",
    "    ent[i] = dt.entropy(v)\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492\n",
      "0.9998153271549207\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "uset = np.random.binomial(1, .5, 1000)\n",
    "p_u = sum(uset)/len(uset)\n",
    "print(p_u)\n",
    "ent_uset = -p_u*np.log2(p_u) - (1-p_u)*np.log2(1-p_u)\n",
    "print(ent_uset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106\n",
      "0.48773158354050183\n"
     ]
    }
   ],
   "source": [
    "eset = np.random.binomial(1, .1, 1000)\n",
    "p_e = sum(eset)/len(eset)\n",
    "print(p_e)\n",
    "ent_eset = -p_e*np.log2(p_e) - (1-p_e)*np.log2(1-p_e)\n",
    "print(ent_eset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07527256 0.00583843 0.00470757 0.0263117  0.28703075 0.00075786]\n",
      " [0.00375618 0.0024585  0.00105615 0.01566425 0.01727718 0.00624762]\n",
      " [0.00712087 0.29373617 0.00083111 0.00289182 0.25591172 0.00707703]]\n"
     ]
    }
   ],
   "source": [
    "len_data = len(datasets)\n",
    "len_att = len(m.attributes)\n",
    "info = np.zeros((len_data, len_att))\n",
    "for i, v in enumerate(datasets):\n",
    "    for j in range(len(m.attributes)):\n",
    "        info[i,j] = dt.averageGain(v, m.attributes[j])\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 1]\n"
     ]
    }
   ],
   "source": [
    "roots = np.argmax(info, axis = 1)\n",
    "print(roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.93831535 0.94807824 0.90817835]\n",
      " [0.91034806 1.         0.96333555 0.877962  ]\n",
      " [0.91829583 0.8296071  0.37764632 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "subent = np.zeros((len_data, 4))\n",
    "for i, x in enumerate(datasets):\n",
    "    att = m.attributes[roots[i]]\n",
    "    for j, v in enumerate(att.values):\n",
    "        subent[i,j] = dt.entropy(dt.select(x, att, v))\n",
    "print(subent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 3. 5. 0.]\n",
      " [2. 2. 2. 1.]\n",
      " [4. 4. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "nodes_1 = np.empty((len_data, 4))\n",
    "for i, x in enumerate(datasets):\n",
    "    att = m.attributes[roots[i]]\n",
    "    for j, v in enumerate(att.values):\n",
    "        subsets = dt.select(x, att, v)\n",
    "        info = np.zeros(len_att)\n",
    "        for k in range(len_att):\n",
    "            info[k] = dt.averageGain(subsets, m.attributes[k])\n",
    "        nodes_1[i,j] = np.argmax(info)\n",
    "print(nodes_1)\n",
    "\n",
    "# mostCommon to find the outcome (+ or -) of each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawt.drawTree(dt.buildTree(m.monk1, m.attributes, 2))\n",
    "#drawt.drawTree(dt.buildTree(m.monk2, m.attributes, 2))\n",
    "drawt.drawTree(dt.buildTree(m.monk3, m.attributes, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.1712963 ]\n",
      " [0.         0.30787037]\n",
      " [0.         0.05555556]]\n"
     ]
    }
   ],
   "source": [
    "testsets = [m.monk1test, m.monk2test, m.monk3test]\n",
    "err = np.zeros((len_data, 2))\n",
    "for i, x in enumerate(datasets):\n",
    "    t = dt.buildTree(x, m.attributes)\n",
    "    err[i, 0] = 1 - dt.check(t, x)\n",
    "    err[i, 1] = 1 - dt.check(t, testsets[i])\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
